import { useState, useEffect, useRef } from 'react';
import micIcon from '../../assets/mic.png';

// ë‹«ê¸° ì•„ì´ì½˜ ì»´í¬ë„ŒíŠ¸ (ì„ì‹œ)
export const XIcon = () => (
    <svg xmlns="http://www.w3.org/2000/svg" className="h-8 w-8 text-gray-700" fill="none" viewBox="0 0 24 24" stroke="currentColor">
        <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M6 18L18 6M6 6l12 12" />
    </svg>
);

export default function AiVoiceModal({ target, isOpen, setIsOpen, onResult, exampleText }) {
    const [isRecording, setIsRecording] = useState(false);
    const mediaRecorderRef = useRef(null);
    const audioChunksRef = useRef([]);
    const [advicePrompt, setAdvicePrompt] = useState('');
    const [isProcessing, setIsProcessing] = useState(false);

    useEffect(() => {
        if (target === "ìƒí’ˆì˜ ì´ë¦„ê³¼ ì„¤ëª…") {
            setAdvicePrompt("ë¼ê³  í–ˆì„ ë•Œ ìƒí’ˆì˜ ì´ë¦„ê³¼ ì„¤ëª…ì„ name, category, price, description í•„ë“œë¡œ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì¤˜. priceëŠ” ìˆ«ìë§Œ, descriptionì€ nameì˜ íŠ¹ì§•ì„ 30ì ì´ë‚´ë¡œ, categoryëŠ” 'ë†ì‚°ë¬¼', 'ì¶•ì‚°ë¬¼', 'ìˆ˜ì‚°ë¬¼', 'ê°€ê³µì‹í’ˆ', 'ë°˜ì°¬' ì¤‘ í•˜ë‚˜ë¡œ ì„¤ì •");
        } else {
            setAdvicePrompt('');
        }
    }, [target]);

    const sendTextToGemini = async (prompt) => {
        const apiKey = import.meta.env.VITE_GEMINI_API_KEY;
        const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20:generateContent?key=${apiKey}`;

        const fullPrompt = `${prompt} ${advicePrompt}`;
        const payload = {
            contents: [{
                parts: [{
                    text: fullPrompt
                }]
            }]
        };

        try {
            setIsProcessing(true);
            const response = await fetch(apiUrl, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(payload)
            });

            if (!response.ok) {
                const errorBody = await response.json();
                throw new Error(`Gemini API ìš”ì²­ ì‹¤íŒ¨: ${response.status} - ${errorBody.error.message}`);
            }

            const result = await response.json();
            
            if (!result.candidates || result.candidates.length === 0) {
                throw new Error("API ì‘ë‹µì—ì„œ ìœ íš¨í•œ í›„ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
            }
            const text = result.candidates[0].content.parts[0].text;
            console.log("Gemini ì‘ë‹µ:", text);

            const jsonString = text.replace(/```json/g, '').replace(/```/g, '').trim();
            const parsedData = JSON.parse(jsonString);

            console.log("íŒŒì‹±ëœ Gemini ì‘ë‹µ:", parsedData);
            
            onResult(parsedData);

        } catch (error) {
            console.error("Gemini API ì—°ë™ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", error);
        } finally {
            setIsProcessing(false);
        }
    };

    // í´ë¡œë°” ìŒì„±ì¸ì‹ API í˜¸ì¶œ í•¨ìˆ˜
    const sendAudioToClova = async (audioBlob) => {
        const clientId = import.meta.env.VITE_NAVER_VOICE_CLIENT_ID; 
        const clientSecret = import.meta.env.VITE_NAVER_VOICE_CLIENT_SECRET;
        
        // âœ… Vite í”„ë¡ì‹œ ì„¤ì •ì— ë§ê²Œ ê²½ë¡œë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤.
        const apiUrl = '/naver-api/recog/v1/stt?lang=Kor';

        console.log('Naver Clova APIë¡œ ìŒì„± ë°ì´í„°ë¥¼ ì „ì†¡í•©ë‹ˆë‹¤...');
        try {
            const response = await fetch(apiUrl, {
                method: 'POST',
                headers: {
                    'X-NCP-APIGW-API-KEY-ID': clientId,
                    'X-NCP-APIGW-API-KEY': clientSecret,
                    'Content-Type': 'application/octet-stream'
                },
                body: audioBlob,
            });

            if (!response.ok) {
                const errorText = await response.text();
                throw new Error(`API ìš”ì²­ ì‹¤íŒ¨: ${response.status} ${response.statusText} - ${errorText}`);
            }

            const result = await response.json();
            console.log('Clova API ì‘ë‹µ ê²°ê³¼:', result);
            
            if (result.text) {
                console.log('ì¸ì‹ëœ í…ìŠ¤íŠ¸:', result.text);
                sendTextToGemini(result.text);
            } else {
                console.log('í…ìŠ¤íŠ¸ë¥¼ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì‘ë‹µ:', result);
            }
        } catch (error) {
            console.error('Clova Speech API ì—°ë™ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', error);
        }
    };

    const toggleRecording = async () => {
        if (isRecording) {
            if (mediaRecorderRef.current) mediaRecorderRef.current.stop();
            setIsRecording(false);
            return;
        }
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            const mediaRecorder = new MediaRecorder(stream);
            mediaRecorderRef.current = mediaRecorder;
            audioChunksRef.current = [];
            mediaRecorder.ondataavailable = (event) => {
                if (event.data.size > 0) audioChunksRef.current.push(event.data);
            };
            mediaRecorder.onstop = () => {
                const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/mp3' });
                sendAudioToClova(audioBlob);
                stream.getTracks().forEach(track => track.stop());
            };
            mediaRecorder.start();
            setIsRecording(true);
            console.log('10ì´ˆ ë™ì•ˆ ë…¹ìŒì„ ì‹œì‘í•©ë‹ˆë‹¤...');
            setTimeout(() => {
                if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
                    mediaRecorderRef.current.stop();
                    setIsRecording(false);
                    console.log('10ì´ˆê°€ ê²½ê³¼í•˜ì—¬ ë…¹ìŒì„ ì¤‘ì§€í•©ë‹ˆë‹¤.');
                }
            }, 10000);
        } catch (error) {
            console.error('ë§ˆì´í¬ ì ‘ê·¼ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:', error);
            alert('ë§ˆì´í¬ ì‚¬ìš© ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
        }
    };

    const closeModal = () => {
        setIsOpen(false);
        setIsRecording(false);
    }

    return (
        <div className={`absolute z-10 w-full h-full bg-gradient-to-b from-[#FFFFFF] via-[#AFDCFF] to-[#FECCFF] ${isOpen ? 'block' : 'hidden'}`}>
            <header className="flex justify-between items-center p-4 mt-8">
                <h1 className="font-black text-xl ml-2">AI ìŒì„±ì¸ì‹</h1>
                <button onClick={closeModal}><XIcon/></button>
            </header>
            <h2 className="flex font-semibold text-lg text-center items-center justify-center mt-[40%] ">
                ì•„ë˜ ë²„íŠ¼ì„ í´ë¦­í•˜ê³ <br/>{target}ì„ ë§í•´ì£¼ì„¸ìš”.
            </h2>
            <div className="flex items-center justify-center mt-[10%]">
                <button
                    onClick={toggleRecording}
                    aria-label={isRecording ? 'ë…¹ìŒ ì¤‘ì§€' : 'ë…¹ìŒ ì‹œì‘'}
                    className={`flex items-center justify-center bg-white w-32 h-32 p-4 rounded-full cursor-pointer focus:outline-none focus:ring-blue-500 ${isRecording ? 'animate-pulse-custom' : 'shadow-lg'}`}
                >
                    <img src={micIcon} className="w-16 h-20" alt="ë§ˆì´í¬ ì•„ì´ì½˜" />
                </button>
            </div>
            <p className="text-lg font-semibold text-center mt-8">
                {isRecording && 'ë…¹ìŒ ì¤‘...'}
                {isProcessing && 'ğŸ¤– AIê°€ ë“¤ì€ ë‚´ìš©ì„ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”ğŸ˜š'}
                {!isRecording && !isProcessing && `âœ… ì˜ˆì‹œ: "${exampleText}"`}
            </p>
        </div>
    );
}